Here’s a complete, receipts-first expansion of **WO-07 — Unanimity on truth blocks (MAJOR)** with the G1 guard baked in, explicit “pull back via Π and S” mapping (frozen), and a harness plan so the reviewer can test only from receipts.

---

# WO-07 — Unanimity on truth blocks (MAJOR)

## Objective

Given the **test truth partition** (P:\Omega_*\to\mathbb{Z}*{\ge 0}) from **WO-05** (on the Π-presented test grid (X**\in\mathcal{C}^{H_*\times W_*})), and for each training (i=1..m):

* the **training input** size in Π-frame ((H_i,W_i)),
* the **training output** (Y_i\in \mathcal{C}^{R_i\times C_i}) (outputs are **not** presented),
* the **frozen S** (WO-02) serialized params for that training’s ((H_i,W_i)\mapsto (R_i,C_i)),
* the Π transforms ( \Pi_* ) (test) and ( \Pi_i ) (training),

compute a **unanimous color** (u(B)) for each truth block (B={p\in\Omega_* \mid P(p)=b}) **iff**:

1. At least one training (i) **defines** a pullback mapping for some pixel in (B) (non-empty “defined set”); and
2. For **every** training (i) that defines it, the set ({,Y_i(p_i)\mid p\in B\land p_i=\mathrm{pb}_i(p),}) is a **singleton**; and
3. All these singletons (per defined training) are **equal** to the same color.

Then record (u(B)) as that color. Otherwise **do not write** (G1: never treat an empty pullback as unanimous).

**This is a read-only consensus channel**; it never guesses and never uses “majority.”

---

## Frozen pullback via Π and S (define-domain rule)

For each pixel (p=(r_*,c_*)\in\Omega_*=[0..H_*-1]\times[0..W_*-1]) and training (i):

1. **Normalize to unit coordinates in the test Π-frame**
   (u = r_*/H_*,\quad v = c_*/W_*).  (Exact division in ([0,1)).)

2. **Map to training output size** using the **frozen S** for that training:
   ((R_i,C_i) = S(H_i,W_i)) (from WO-02 serialized params; **do not re-fit S**).
   (\quad r_i = \lfloor u \cdot R_i \rfloor,; c_i = \lfloor v \cdot C_i \rfloor.)

3. **Bounds check** (define-domain rule):
   If (0 \le r_i < R_i) and (0 \le c_i < C_i), then (p_i=(r_i,c_i)) is **defined**; else **undefined** for training (i).

> This “Π+S pullback” is frozen and **must be used verbatim**; no adaptive warps, no nearest-band heuristics.

---

## Deliverables

### `arc/op/unanimity.py`

```python
from __future__ import annotations
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple
import numpy as np
from blake3 import blake3

@dataclass
class BlockVote:
    block_id: int
    color: Optional[int]              # None if not unanimous
    defined_train_ids: List[str]      # trainings that had at least one defined pixel in this block
    # optional diagnostics
    per_train_colors: Dict[str, List[int]]  # unique colors per training (empty => undefined)
    pixel_count: int                  # |B|
    defined_pixel_counts: Dict[str, int]    # #defined p in B per training

@dataclass
class UnanimityRc:
    blocks_total: int
    unanimous_count: int
    empty_pullback_blocks: int
    disagree_blocks: int
    # optional: hash of (block_id,color or None, defined_train_ids) table for determinism
    table_hash: str
    blocks: List[BlockVote]           # full list for audit (or keep minimal if size is a concern)

def compute_unanimity(
    truth_blocks: np.ndarray,                         # H* x W*, int block ids from WO-05
    test_shape: Tuple[int,int],                       # (H*, W*) in Π frame
    train_infos: List[Tuple[str, Tuple[int,int], Tuple[int,int], np.ndarray]], 
    # list of (train_id, (H_i,W_i), (R_i,C_i), Y_i array of shape R_i x C_i)
) -> UnanimityRc:
    """
    For each truth block B in test Π-frame, apply frozen Π+S pullback to each training's output grid.
    If at least one training defines B, and all defined trainings have constant & equal color on B, emit that color.
    Otherwise None (no unanimity).
    """
```

**Inputs:**

* `truth_blocks`: `np.ndarray[int32]` of shape ((H_*,W_*)) from WO-05.
* `test_shape = (H_\*,W_\*)` (redundant but used to avoid mismatches).
* `train_infos`: for each training `tid`

  * `(H_i, W_i)` **presented** input size (from WO-01, Π applied to training input),
  * `(R_i, C_i)` from **WO-02 S** serialized params (reconstructed once),
  * `Y_i` (raw output grid, shape (R_i\times C_i)).
    (We do **not** need `phi*` here; unanimity ignores φ.)

---

## Algorithm (deterministic)

1. Precompute `H*,W* = truth_blocks.shape`.
   Validate each `train_infos[i]` has consistent `R_i,C_i` with its `Y_i.shape`.

2. For every **block id** (b) in `truth_blocks`:

   * `coords = np.argwhere(truth_blocks == b)`; `pixel_count = len(coords)`.
   * For each training (i), compute:

     * For each (p\in coords): pull back to ((r_i,c_i)) via frozen mapping; if defined, collect (Y_i[r_i,c_i]).
     * Let `S_i = set(collected_colors)`.
     * If `|S_i|==0`: training `i` is **undefined** on this block.
       If **all** trainings undefined ⇒ **empty pullback** ⇒ **no unanimity** (record `empty_pullback_blocks += 1`, `defined_train_ids=[]`).
     * Else if `|S_i|>1`: **disagreement within training i** ⇒ block **not unanimous** (record `disagree_blocks += 1`).
   * After iterating trainings:

     * `defined_train_ids = { i | |S_i|>0 }`.
     * If `defined_train_ids` is non-empty and **every** `S_i` is a singleton and **all singleton values equal** the same color `u`, then **unanimous**:

       * `color = u`, `unanimous_count += 1`.
     * Else `color = None` (no unanimity).

3. **Receipts:**

   * For each block: `BlockVote(block_id=b, color, defined_train_ids, per_train_colors=… , pixel_count, defined_pixel_counts=…)`.
   * Aggregate: `UnanimityRc(blocks_total, unanimous_count, empty_pullback_blocks, disagree_blocks, table_hash=blake3(…))`.
   * `table_hash` can be the BLAKE3 of a deterministic byte encoding of `(block_id, color or -1, sorted defined_train_ids)` for all blocks.

**G1 enforcement:** We only emit a color if `defined_train_ids` is non-empty **and** all defined trainings agree internally and with each other. No training ⇒ no write.

---

## Receipts (first-class, audit-friendly)

* `blocks`: list of `BlockVote` with **exact** `defined_train_ids` per block.
* `unanimous_count`, `empty_pullback_blocks`, `disagree_blocks`.
* `table_hash` to make the entire decision table immutable and comparable across runs.
* Optional: `pullback_frame: "presented"`, `shape_source: "WO-02.params"`, `truth_source: "WO-05.partition_hash"` for provenance.

---

## Harness (WO-07 branch in `scripts/run_wo.py`)

1. Load for each task id:

   * WO-01 Π receipts for test/trains (to confirm frames; sizes).
   * WO-02 **ShapeRc** (deserialize `S` to get each (R_i,C_i); ensure `frame=="presented"`).
   * WO-05 `TruthRc` and `TruthPartition` for the test; take `blocks = truth.blocks`.
   * The **raw training outputs** (Y_i).

2. Run:

```bash
python -m scripts.run_wo --wo WO-07 --data data/raw/ --subset data/ids.txt \
  --out out/ --receipts out/receipts/
```

* For each task call `compute_unanimity(blocks, (H*,W*), train_infos)`.
* Write JSONL per task with `unanimity = UnanimityRc` (full or summarized plus `table_hash`).

3. **Determinism:** run twice; receipts must exactly match. Print a summary:

```
WO-07: tasks=N, blocks_total=…, unanimous=…, empty_pullbacks=…, disagreements=…
```

4. **Acceptance:**

   * Use a “frame fill” family (e.g., **23b5c85d**) where training outputs fill entire border or a fixed block color; expect several `BlockVote.color` to be the same across trainings; confirm **non-empty defined_train_ids**; confirm block-level unanimity equals ground truth.
   * Cross-check: pick a block whose pullback is empty on all trainings → `color=None`, `defined_train_ids=[]`, and `empty_pullback_blocks` increments.

5. **Red-team:**

   * Force one training’s output to be smaller so some blocks pull back out of bounds → `defined_train_ids` excludes that training; unanimity persists only if remaining defined trainings agree.
   * Force two trainings to disagree on a block’s color → `disagree_blocks` increments; `color=None`.

---

## Integration with WO-09 (Meet)

* The unanimity product for each block (B) is a candidate set
  ({u(B)}) iff `BlockVote.color` is not `None`.
* In **WO-09** you’ll implement the fixed priority `copy ▷ law ▷ unanimity ▷ bottom`; here you provide the `block_color_map: Dict[int,int]` (block_id → color) and the full `UnanimityRc`. The meet writer will paint color `u(B)` for all (p\in B) **only if** neither `copy` nor `law` provided a value for that (p).

---

## Reviewer checklist (MAJOR)

* [ ] **G1 enforced**: any block with `defined_train_ids==[]` yields `color=None`; `empty_pullback_blocks` > 0 on constructed empty-pullback tests.
* [ ] For unanimous blocks, `defined_train_ids` is non-empty and **all** defined trainings agree internally (receipts `per_train_colors[tid]` has size 1) and across trainings (all singletons equal).
* [ ] Determinism: receipts identical across runs; `table_hash` stable.
* [ ] Provenance: S comes from **WO-02 params** and test frame is **presented** (no refit / no RAW sizes).
* [ ] No use of majority/voting; no heuristics; no dynamic features.

---

## Notes / discussion

* **Why not use φ here?** Unanimity is a disjoint channel: it infers **constant block colors** directly from training outputs via **Π+S** normalized coordinates and the truth partition. It’s orthogonal to φ and must ignore “majority.”
* **Why this mapping?** The addendum requires unanimity to respect Π (presented frames) and **frozen** shape pullback; we encode that mapping explicitly to eliminate ambiguity.
* **Scalability:** H,W ≤ 30 → block iteration is cheap. Still, you can pre-group pixels by block id once (from `truth.blocks`) and reuse the groups.
