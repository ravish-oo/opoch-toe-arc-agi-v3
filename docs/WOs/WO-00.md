Awesome — kicking off with the first brick.

# WO-00 — Repo scaffold + receipts kernel (expanded implementer brief)

## Objective

Stand up the deterministic spine so every later WO returns `(value, receipt)`, and the harness can prove determinism (double-run same receipts) and environment capture. No heuristics, no float drift. Palette/D4/anchor and the rest come later — this WO is only bytes, hashes, receipts, and a tiny runner shell that exercises the determinism loop (using placeholders where Π will slot in). This aligns the program with the math/engineering operator framing and the receipts canon (palette/pose/anchor receipts are referenced here but implemented in WO-01).  

---

## File tree (exact paths)

```
arc-agi-operator/
├─ pyproject.toml
├─ README.md
├─ docs/anchors/
│  ├─ 00_math_spec.md
│  ├─ 01_engineering_spec.md
│  └─ 02_determinism_addendum.md
├─ data/
│  ├─ raw/              # ARC tasks json
│  └─ ids.txt
├─ out/
│  ├─ receipts/
│  └─ y_pred/
├─ scripts/
│  ├─ run_wo.py
│  └─ check_receipts.py
└─ arc/
   ├─ __init__.py
   ├─ io/
   │  ├─ __init__.py
   │  ├─ load_data.py
   │  └─ save.py
   └─ op/
      ├─ __init__.py
      ├─ bytes.py
      ├─ hash.py
      └─ receipts.py
```

(Repo structure matches the repository spec you locked; WO-01.. later files come in later WOs.)

---

## Dependencies (frozen)

Python 3.11+. Libraries: `blake3`, `numpy` (no float FFT here). Determinism note in README.

**pyproject.toml**

```toml
[project]
name = "arc-agi-operator"
version = "0.0.1"
requires-python = ">=3.11"
dependencies = [
  "blake3==0.4.1",
  "numpy==1.26.4"
]

[tool.ruff]
line-length = 100
```

---

## Modules to implement

### 1) `arc/op/bytes.py` — canonical encodings (BLOCKER)

Implements the frozen grid and integer encodings (uint32_le; ZigZag LEB128; LEB128 varints). This exactly enforces the addendum’s global invariants. 

**Contract**

* `to_bytes_grid(G: np.ndarray) -> bytes`
  Encode H×W np.int64/np.int32 colors as uint32 little-endian row-major bytes.
* `zigzag_encode(i: int) -> bytes`
  Return ZigZag-encoded LEB128 varint.
* `varu(n: int) -> bytes`
  Unsigned LEB128 varint.
* `frame_params(*ints: int, signed: bool=False) -> bytes`
  `<count><p1>…<pk>` using LEB128; ZigZag if signed=True.
* `from_bytes_grid(b: bytes, shape: tuple[int,int]) -> np.ndarray`
  (Used only in property tests; not required later.)

**Notes**

* Overflow → raise `ValueError`.
* No floats anywhere. (We’ll use these encoders to serialize params/receipts consistently.)

**Skeleton**

```python
# arc/op/bytes.py
from __future__ import annotations
import numpy as np

def to_bytes_grid(G: np.ndarray) -> bytes:
    if G.dtype.kind not in "iu":
        raise TypeError("Grid must be integer dtype")
    g32 = G.astype(np.uint32, copy=False).T.byteswap(False).T  # keep row-major
    return g32.tobytes(order="C")

def _zigzag(i: int) -> int:
    return (i << 1) ^ (i >> 63) if i < 0 else (i << 1)

def zigzag_encode(i: int) -> bytes:
    return varu(_zigzag(i))

def varu(n: int) -> bytes:
    if n < 0:
        raise ValueError("varu expects unsigned")
    out = bytearray()
    while True:
        byte = n & 0x7F
        n >>= 7
        if n:
            out.append(byte | 0x80)
        else:
            out.append(byte)
            break
    return bytes(out)

def frame_params(*ints: int, signed: bool=False) -> bytes:
    out = bytearray()
    out += varu(len(ints))
    for v in ints:
        out += zigzag_encode(v) if signed else varu(v)
    return bytes(out)
```

---

### 2) `arc/op/hash.py` — hashing helpers (BLOCKER)

BLAKE3 over bytes; grid hashing uses **uint32_le row-major**. 

**Contract**

* `hash_bytes(b: bytes) -> str` → hex
* `hash_grid(G: np.ndarray) -> str` → hex, using `to_bytes_grid`

**Skeleton**

```python
# arc/op/hash.py
from __future__ import annotations
from blake3 import blake3
import numpy as np
from .bytes import to_bytes_grid

def hash_bytes(b: bytes) -> str:
    return blake3(b).hexdigest()

def hash_grid(G: np.ndarray) -> str:
    return hash_bytes(to_bytes_grid(G))
```

---

### 3) `arc/op/receipts.py` — receipts kernel (BLOCKER)

Defines typed receipts (dict-like dataclasses) and an aggregator that creates a single JSON-serializable blob per task/run, plus env_fingerprint; used by every WO. This is the first-class receipts plumbing demanded by the math/engineering specs.  

**Contract**

* Dataclasses: `EnvRc`, `RunRc` (root container), and placeholders for Π/Shape/… (we’ll extend as WOs land).
* `env_fingerprint() -> EnvRc`  (platform, endian, python/blake3 versions, build flags hash placeholder)
* `aggregate(run: dict) -> dict`
  Shallow freeze: ensure keys exist, hashes are hex strings.

**Skeleton**

```python
# arc/op/receipts.py
from __future__ import annotations
import platform, sys, json
from dataclasses import dataclass, asdict
from .hash import hash_bytes

@dataclass
class EnvRc:
    platform: str
    endian: str
    py_version: str
    blake3_version: str
    compiler_version: str | None
    build_flags_hash: str

def env_fingerprint() -> EnvRc:
    endian = "little" if sys.byteorder == "little" else "big"
    # blake3 exposes version via package metadata; keep static as placeholder
    b3v = "0.4.1"
    comp = platform.python_compiler()
    flags = hash_bytes(json.dumps({"py": sys.version, "impl": platform.python_implementation()}).encode())
    return EnvRc(
        platform=platform.platform(),
        endian=endian,
        py_version=platform.python_version(),
        blake3_version=b3v,
        compiler_version=comp,
        build_flags_hash=flags
    )

@dataclass
class RunRc:
    env: EnvRc
    stage_hashes: dict  # e.g., {"pi.roundtrip_hash": "...", "truth.partition_hash": "..."}
    notes: dict | None = None

def aggregate(run: dict) -> dict:
    # Accept nested dataclasses or plain dicts and produce a JSON-serializable dict
    def to_plain(x):
        if hasattr(x, "__dataclass_fields__"):
            return {k: to_plain(v) for k, v in asdict(x).items()}
        if isinstance(x, dict):
            return {k: to_plain(v) for k, v in x.items()}
        if isinstance(x, (list, tuple)):
            return [to_plain(v) for v in x]
        return x
    return to_plain(run)
```

---

### 4) `arc/io/load_data.py` & `arc/io/save.py` — minimal I/O

Simple JSON loader for ARC tasks (used by scripts).

```python
# arc/io/load_data.py
from __future__ import annotations
import json, os
from typing import Any

def load_task(path: str) -> dict[str, Any]:
    with open(path, "r") as f:
        return json.load(f)
```

```python
# arc/io/save.py
from __future__ import annotations
import json, os
from typing import Any

def write_json(path: str, obj: Any) -> None:
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w") as f:
        json.dump(obj, f, separators=(",", ":"))
```

---

### 5) `scripts/run_wo.py` — harness shell (BLOCKER)

Runs **WO-00** twice, records env receipts, checks determinism. Later WOs extend this.

**Behavior**

* Args: `--wo WO-00`, `--data data/raw/`, `--subset data/ids.txt`, `--out out/`, `--receipts out/receipts/`.
* For WO-00, we don’t compute Π or outputs; we just demonstrate determinism and write a JSONL with env and placeholder stage hashes.

**Skeleton**

```python
# scripts/run_wo.py
from __future__ import annotations
import argparse, os, time, json
from arc.op.receipts import env_fingerprint, aggregate
from arc.op.hash import hash_bytes

def run_once() -> dict:
    env = env_fingerprint()
    # Placeholder stage_hashes; WO-01.. will add real ones
    stage_hashes = {"wo": "WO-00", "ts": str(time.time_ns())}
    run_rc = {"env": env, "stage_hashes": stage_hashes}
    return aggregate(run_rc)

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--wo", default="WO-00")
    ap.add_argument("--receipts", default="out/receipts/")
    args = ap.parse_args()
    os.makedirs(args.receipts, exist_ok=True)

    r1 = run_once()
    r2 = run_once()

    # determinism: env must match; for WO-00 stage hashes are placeholders,
    # but we enforce env equality; later WOs enforce full receipts equality.
    if r1["env"] != r2["env"]:
        print("NONDETERMINISTIC_ENV")
        exit(2)

    # Write receipts JSONL
    outp = os.path.join(args.receipts, f"{args.wo}_run.jsonl")
    with open(outp, "w") as f:
        f.write(json.dumps(r1) + "\n")
        f.write(json.dumps(r2) + "\n")

    print(f"OK {args.wo} receipts written → {outp}")

if __name__ == "__main__":
    main()
```

### 6) `scripts/check_receipts.py` — diff receipts (BLOCKER)

```python
# scripts/check_receipts.py
from __future__ import annotations
import json, sys

def load_jsonl(path: str):
    with open(path) as f:
        return [json.loads(line) for line in f]

def main():
    a, b = sys.argv[1], sys.argv[2]
    A, B = load_jsonl(a), load_jsonl(b)
    if A == B:
        print("RECEIPTS_MATCH")
        return
    print("RECEIPTS_DIFFER")
    # Print first diff key (shallow)
    print(A[0].keys() ^ B[0].keys())
    sys.exit(1)

if __name__ == "__main__":
    main()
```

---

## README.md additions (short)

* What this repo is (single commuting operator; receipts-first).
* How to run this WO:

```bash
python -m scripts.run_wo --wo WO-00 --receipts out/receipts/
python -m scripts.check_receipts out/receipts/WO-00_run.jsonl out/receipts/WO-00_run.jsonl
```

---

## Receipts for WO-00 (what must exist)

* `env_fingerprint = {platform, endian, py_version, blake3_version, compiler_version, build_flags_hash}` (frozen keys; compare across runs).
* Later WOs will add stage hashes like `pi.roundtrip_hash`, `truth.partition_hash`, etc., per the addendum’s schema. 

---

## Proof obligations (PO) & Acceptance (real ARC)

**PO**

1. `env_fingerprint` identical across double run (determinism harness; raises `NONDETERMINISTIC_ENV` otherwise).
2. Placeholder metamorphic: once Π exists, `hash_grid(Π(G)) == hash_grid(Π(Π(G)))` (asserted in WO-01 acceptance). 

**Acceptance**

* Run the command above; verify `OK WO-00` and JSONL written; re-run and compare with `check_receipts.py` — must match exactly.

**Red-team**

* Manually tweak `PYTHONHASHSEED`/env to simulate env wobble; ensure the harness flags `NONDETERMINISTIC_ENV`.

---

## Reviewer checklist (BLOCKER)

* [ ] `arc/op/bytes.py` implements uint32_le grid serialization; ZigZag LEB128; varints; `frame_params`.
* [ ] `arc/op/hash.py` uses `to_bytes_grid` → BLAKE3 hex.
* [ ] `arc/op/receipts.py` has `EnvRc`, `RunRc`, `env_fingerprint()`, `aggregate()`.
* [ ] `scripts/run_wo.py` double-runs and enforces env equality; writes JSONL in `out/receipts/`.
* [ ] Determinism pass: two runs produce equal receipts.

---

## Why this satisfies anchors

* **Math spec**: sets the operator’s audit trail normalization; later steps compute Π, Truth gfp, Witness intersection, and Meet. This WO ensures we can *prove* idempotence and fixed-point behaviors once they land by hashing the canonical encodings. 
* **Engineering spec**: explicit contracts for Π/S/Witness/Truth/Meet receipts; this WO provides the receipts substrate and deterministic hashing encodings (uint32_le, varints). 
* **Determinism addendum**: enforces global invariants (uint32_le, ZigZag/varint), receipts’ environment fingerprint, and the determinism harness requirement from day one. 

---

## Hand-off to Implementer (copy/paste)

* Create files exactly as above; keep function names/signatures intact.
* Do not add files or folders.
* Return a PR with: code + a sample `out/receipts/WO-00_run.jsonl` from your machine.
* Do **not** stub beyond these; this WO is ≤ ~200 LOC.

## Hand-off to Reviewer/Tester

* Run the two commands in README.
* Confirm JSONL contains `env` key with all fields and that both lines are identical.
* If any field differs, block the WO.

---

When you say **“lock WO-00”**, I’ll generate a one-pager for Claude Code with the exact file contents collapsed and a ready-to-paste README section so they can implement without deviating.
