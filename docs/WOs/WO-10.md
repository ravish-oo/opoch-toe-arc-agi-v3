 **WO-10 — Family adapters (symbolic slice/band emitters)** in a receipts-first, deterministic way and wire it to WO-05/WO-04/WO-08/WO-11. This implements the finite “Spec-B” engines (esp. **Column-Dictionary**) and bakes in A1/A2, B1/B2, C1/C2 so the reviewer can catch any drift from receipts alone.

---

# WO-10 — Family adapters (symbolic slice/band emitters) (MINOR)

## Objective

When **WO-04** ends in a *summary* law (no φ) or when a finite archetype reproduces trainings exactly, synthesize the test output (\tilde Y_*) **without guessing** by running **frozen finite engines** that use **WO-05 Truth features**. Each engine:

1. **Fits** on trainings with exact rules (no thresholds, no learning beyond dictionaries).
2. **Verifies reconstruction** on every training output exactly.
3. **Emits full receipts** (schema, candidate sets and counts, tie keys).
4. **Applies** to test; if any lookup is missing → **fail-closed** with a precise receipt.
5. **Imposes small shape** (R,C) when WO-02 was `SHAPE_CONTRADICTION`.
6. Hands placement ties to **WO-08 Tie-break L** when multiple exact reconstructions exist.

### Dependencies

* **WO-05 (Truth):** `TruthRc` (`row_clusters`, `col_clusters`, `per_color_overlap`, optional row/col non-zero masks).
* **WO-04:** summary-law receipts (A1/C2 candidate sets & per-color counts) for provenance.
* **WO-08:** tie-break `resolve(...)` for placement ties (`tie_context` = `"generic_placement"` or `"skyline"`).
* **WO-11:** runner invokes engines in a **frozen order** and records engine receipts.

---

## Engines (frozen order in runner)

1. **Border-Scalar** (if you implement): max border 4-CC → min interior 4-CC → smallest color (tie chain frozen).
2. **Window-Dictionary / Column-Dictionary** (this WO delivers Column-Dictionary first).
3. **Macro-Tiling** (bands + per-tile strict foreground majority).
4. **Pooled-Blocks** (stage-1 votes → pooled quadrants; frozen override).
5. **Markers-Grid** (2×2 marker centroids, strict fill).
6. **SliceStack / Kronecker** (stacked fixed motifs; e.g., **652646ff** and **ccd554ac**).

Each engine has `fit(...)` and `apply(...)`; receipts must state which **engine** succeeded (`engine: "column_dict" | "macro_tiling" | ...`) and the deterministic artifacts used.

---

## Engine 1 — Column-Dictionary (fixes 3f7978a0-class)

### Fit (trainings → dict)

* **Signature schema (frozen v1):**
  `schema_id: "col_sig_v1"`,
  ( \texttt{sig}(j) = (\text{has8},\ \text{has5}) \in {0,1}^2 ) for each input column (j) of Π(train (X_i)).

  * `has8 = 1[∃r: X_i[r,j]==8]`
  * `has5 = 1[∃r: X_i[r,j]==5]`
* **Squash runs** of equal signatures (run-length encode): `S_i = [s_1,…,s_{w_i}]`.
* **Build dictionary** from outputs (Y_i) (raw): map the **k-th squashed signature** to the **k-th output column vector** (Y_i[:,k]).

  * If a signature (s) occurs with different column vectors across trainings, apply **frozen lex tie** on the raw column bytes and record the **tie table**; the map becomes `dict[s] = lex_smallest_column`.
* **Verify reconstruction**: concatenate `dict[s]` for all `s ∈ S_i` and assert exact equality to (Y_i). If any training fails, engine **does not fit**.

**Receipts (fit):**

```jsonc
{
  "engine": "column_dict",
  "schema_id": "col_sig_v1",
  "train": [
    {
      "train_id": "...",
      "col_signatures": [[has8,has5], ...],             // per column j
      "squashed": [[h8,h5], ...],                       // run-end sequence S_i
      "out_width": w_i,
      "fit_verified": true
    }, ...
  ],
  "dict": { "00": [..column bytes..], "10": [...], "01": [...], "11": [...] },
  "tie_breaks": { "10": { "cands": [[...],[...]], "chosen": 0 } }, // if any
  "fit_verified_on": ["t1","t2","t3"]
}
```

**A1/A2 compliance**

* **Candidate sets** (which colors can appear in columns) must come from **trainings only**.
* No “most frequent in test.” If a squashed signature never appeared in trainings, we **fail-closed** on apply (see below).

### Apply (test)

* Compute column signatures on Π(test), **same schema_id**.
* Squash to `S_*`; for each `s ∈ S_*`:

  * If `s` **in dict** → append `dict[s]` to output.
  * Else **fail-closed** with a receipt:

    ```json
    {"error":"UNSEEN_SIGNATURE","signature":[has8,has5],"position":k}
    ```
* The **small shape** is implied:
  `R = len(out_col)`, `C = len(S_*)` (constant R across trainings by fit proof).
* If multiple placements/alignments produce identical reconstructions (rare), build **candidates** with **placement refs** and call **WO-08** with `tie_context="generic_placement"`. Record `TieBreakRc` and selected placement.

**Receipts (apply):**

```jsonc
{
  "engine": "column_dict",
  "schema_id": "col_sig_v1",
  "test_squashed": [[h8,h5], ...],
  "lookup": [{"sig":[h8,h5],"col_hex":"...","index":k}, ...],
  "final_shape": [R, C],
  "unseen": [] // or [{"sig":[...],"index":k}] if fail-closed
}
```

### Schema evolution (frozen rule)

If a fit fails because one signature ID conflates two different output columns **consistently** across trainings, bump schema to **v2** (extend with a new bit), refit deterministically:

* `col_sig_v2`: `(has8, has5, has_both)` where `has_both = 1[(has8==1 and has5==1)]`.
* Or `double8` if needed: two disjoint 8-components in column.
  **Receipts must state the schema explicitly** (`schema_id`, and optionally `schema_hash` = BLAKE3 of the field list).

---

## Engine 2 — Macro-Tiling (bands + per-tile strict majority)

* Use **WO-05** `row_clusters`, `col_clusters` to form a coarse (r\times c) tiling.
* For each tile, compute **per-color counts**; restrict candidate set (A1) to frozen `\(\mathcal F\)` (**from trainings** or from WO-04 summary receipts), background set `\(\mathcal B\)` fixed (e.g., `{0,1}`).
* **Decision rule (C2):**

  * If a **strict majority** in (\mathcal F) → choose that color;
  * Else if empty tile → **fill with border/background** (A2; record `{"empty":true,"fill":bg}`);
  * Else (tie) → choose **smallest color** in (\mathcal F) (or fallback (7) if that’s the frozen family rule);
  * Record `decision_rule` string (e.g., `"strict_majority_F_fallback_bg_smallest"`).
* Verify per-training: refit the same band edges from WO-05 (same `row_clusters/col_clusters`) and confirm the rendered (Y_i) exactly matches training outputs.

**Receipts:**

```jsonc
{
  "engine":"macro_tiling",
  "row_bands":[0, r1, r2, ...], "col_bands":[0, c1, c2, ...],
  "foreground_colors":[...], "background_colors":[...],
  "tiles":[
    {"band_rc":[bi,bj], "counts":{ "0":..,"5":..,"8":.. }, "decision":"8", "rule":"strict_majority_F_fallback_0"},
    ...
  ],
  "fit_verified_on":[...],
  "final_shape":[R,C]
}
```

**B1/B2 compliance:**

* If there is a **two-stage** rule (block votes → pooled quadrants), record **both** stage-1 votes **and** stage-2 pooled results.

---

## Engine 3 — Pooled-Blocks (two-stage voting)

* Stage-1: per-block votes with frozen (\mathcal F,\mathcal B); record per-block counts and winners.
* Stage-2: pool into quadrants or larger groups per family spec; record pooled decisions and any **frozen override** (e.g., enforce border continuity).
* Verify exact reconstruction on trainings.

**Receipts:** include **both stages** and `decision_rule` strings.

---

## Engine 4 — Markers-Grid (2×2 centroids)

* From WO-05 `per_color_overlap` and `row/col_nonzero_mask`, extract 2×2 solid marker cells; cluster by centroids (exact; no epsilon).
* Fill the coarse grid per family rule (A2 on empty cells).
* Verify exact recon on trainings.

**Receipts:**

* `centroids:[(r,c,color), ...]`, `clusters:[...]`, per-cell fill decisions with `{"marker_color":k}` or `{"empty":true,"fill":bg}`.

---

## Engine 5 — SliceStack / Kronecker (652646ff, ccd554ac)

* **SliceStack:** build an ordered list of motif columns/rows from trainings, ordered by **first Π-raster appearance**; prefer **max-rect anchor** for skyline families; render stacks left→right (C1 “skyline” chain).
* **Kronecker:** verify self-tiling (dictionary of base tile) and render via (\text{tile} \otimes J_H).
* Verify exact recon.

**Receipts:**

* SliceStack: `order:[{col_hex:..., x0:..}, ...]`, `tie_context:"skyline"`, and if multiple placements reproduce trainings, pass candidates to **WO-08** with `tie_context="skyline"`.
* Kronecker: `base_tile_hash`, `repeat_grid:[r,c]`, proof of periodicity (exact_tile flag from WO-05), `final_shape`.

---

## Module surface

### `arc/op/families.py`

```python
from __future__ import annotations
from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Tuple

@dataclass
class EngineFitRc:
    engine: str
    ok: bool
    receipt: Dict[str, Any]             # complete fit receipts
    # If ok, include the frozen spec/state needed for apply (e.g., dict, schema_id, bands…)

@dataclass
class EngineApplyRc:
    engine: str
    ok: bool
    Yt: Optional[np.ndarray]            # Π(test) output if ok
    final_shape: Optional[Tuple[int,int]]
    receipt: Dict[str, Any]             # apply receipts (lookup, final shape, errors)
    # If multiple placements: include Candidate[] and TieBreakRc; else None

def fit_column_dict(train_Xt_list: List[np.ndarray], train_Y_list: List[np.ndarray]) -> EngineFitRc: ...
def apply_column_dict(test_Xt: np.ndarray, fit_rc: EngineFitRc) -> EngineApplyRc: ...

def fit_macro_tiling(train_Xt_list, train_Y_list, truth_list) -> EngineFitRc: ...
def apply_macro_tiling(test_Xt, truth: TruthRc, fit_rc: EngineFitRc) -> EngineApplyRc: ...

# pooled_blocks, markers_grid, slice_stack, kronecker … analogous
```

Each `fit_*` returns `ok=False` with a receipt explaining why it didn’t fit (e.g., conflicting dict entries; `schema_conflict`; per-tile strict majority not met in trainings), never raises.

---

## Receipts — first-class at all levels

* Every engine emits a **complete fit receipt** (what was learned and why it’s unique) and an **apply receipt** (how test was rendered, with exact lookups/pooling/placements).
* Candidate-set receipts (A1) are explicit: `foreground_colors`, `background_colors`, **per-color counts** per tile/window.
* A2: empty slot is **never guessed**; record `{"empty":true,"fill": border}`.
* B1/B2: record **stage-1** and **stage-2** artifacts and **replication windows** (top-left indices) for motifs.
* C1: when placement tie arises, emit **placement keys** and pass to **WO-08** with `tie_context` set; record `TieBreakRc`.
* C2: record exact `decision_rule` strings (e.g., `"strict_majority_F_fallback_0_smallest"`).

---

## Harness (WO-10 branch in `scripts/run_wo.py`)

1. **Inputs per task**

   * Π(test) `Xt`; trainings `Xt_i` + raw `Y_i`.
   * Truth: `TruthRc` for test and trainings (for band engines).
   * Summary provenance from WO-04 (if used): `foreground_colors`, `background_colors`, per-color counts.

2. **Run engines in frozen order**, collect first that fits all trainings; else **engine pipeline fails** (runner will fall back to witness).

3. **Record receipts**: fit + apply receipts; if engine implies small shape, set `shape_source="engine"` and `final_shape` in receipt (runner will store it under Shape).

4. **Determinism**: run twice; receipts identical.

5. **Acceptance**

   * **7bb29440**: band grid via Macro-Tiling — check `row_bands/col_bands`, tile counts, strict majority & rule receipts; final matches gold.
   * **652646ff**: SliceStack — order list, max-rect anchor tie chain, left→right replication.
   * **ccd554ac**: Kronecker tiling — base tile proof and tensor replication.
   * **3f7978a0**: Column-Dictionary — schema v1, dict, squashed signatures; final matches gold or fail-closed on unseen signature.

6. **Red-team**

   * A1: drop color `7` from (\mathbb F) → receipts show `foreground_colors` missing 7; reviewer blocks.
   * A2: fill an empty tile with “most frequent” → receipts will miss the `{"empty":true,"fill":bg}` record; reviewer blocks.
   * B1/B2: emit only stage-1 votes or forget replication windows → receipts incomplete; reviewer blocks.
   * C1: change placement order → `TieBreakRc.chosen_idx` flips across shuffles → harness catches via table_hash mismatch.
   * C2: use mode instead of strict majority → rule string wrong; counts contradict chosen color.

---

## Integration with WO-11 (Hybrid runner)

* **Runner order (frozen):** Engines (as above) → if none fits, call **WO-04 witness** (possibly truth-assisted) and then **WO-08** if underdetermined.
* **Shape propagation:** If **WO-02** was `SHAPE_CONTRADICTION`, the selected engine’s `final_shape` becomes `ShapeRc.R/C` (with `shape_source:"engine"` in receipts).
* **Tie-break:** When engine returns placement candidates, call `tiebreak.resolve(..., tie_context="generic_placement"|"skyline")`.

---

## Summary of mistake guards wired in

* **A1**: Freeze candidate sets from trainings; log `foreground_colors`, `background_colors`, **per-color counts** per decision unit.
* **A2**: Represent empties explicitly in receipts (`{"empty":true,"fill": border}`); never infer from test.
* **B1/B2**: Log **stage-1** and **stage-2** tables, and **replication windows**; verify reconstruction exactly.
* **C1**: No ad-hoc placement—encode keys (center L1, topmost, leftmost; or skyline keys) and hand to WO-08; log `TieBreakRc`.
* **C2**: Use **strict majority** with frozen fallback; log `decision_rule` and counts.

Everything is receipts-first, frozen, and deterministic; no tunables, no searching.